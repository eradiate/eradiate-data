{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eradiate — Level-1 and Level-2 Interfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will see how to interact with Eradiate using its less abstract interfaces. Throughout our progression, we will progressively build a simple scene, visualise it and perform very simple computations. We will explore the many possiblities we have to generate our scene and see in which situation each interface is best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The kernel interface (Level-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first see how to directly interact with Eradiate's computational kernel. Loading the kernel submodule is as simple as importing it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eradiate.kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will load the embedded Mitsuba kernel. Prior to usage, selecting a Mitsuba variant is mandatory. This is done using the `set_variant` function. We are going to work in monochromatic mode, without polarisation, and we therefore select the double-precision monochromatic variant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eradiate.kernel.set_variant(\"scalar_mono_double\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this is done, we can load a scene specified as an XML file. The proposed scene consists of a rectangular surface topped by a slab of participating medium featuring only Rayleigh scattering. The scene is illuminated by a directional source with a intensity of the same order of magnitude as the Sun's. We can take a look at the XML file, then come back here.\n",
    "\n",
    "To load the scene into the computational kernel, we use the `load_file` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eradiate.kernel.core.xml import load_file\n",
    "scene = load_file(\"scene.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the scene file has variable arguments which can be used to specify scene parameters upon loading. For example, we can change the resolution of the perspective camera as well as the number of samples per pixel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = load_file(\"scene.xml\", res=64, spp=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the `Scene` class has a string representation, we can visualise the scene contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the computation defined in the scene file is then done by calling the integrator's `render` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = scene.sensors()[0]\n",
    "scene.integrator().render(scene, sensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For future use, we'll pack this into a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(scene):\n",
    "    sensor = scene.sensors()[0]\n",
    "    scene.integrator().render(scene, sensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the computation is complete, we can visualise the results using the matplotlib plotting package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data = np.array(sensor.film().bitmap())\n",
    "plt.imshow(np.squeeze(data))\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we'll write this as a function for convenience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(scene):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    sensor = scene.sensors()[0]\n",
    "    data = np.array(sensor.film().bitmap())\n",
    "    plt.imshow(np.squeeze(data))\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now change the scene parameters to increase the number of samples per pixel so as to reduce noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = load_file(\"scene.xml\", res=64, spp=4096)\n",
    "render(scene)\n",
    "plot(scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scene we just rendered can also be loaded from a Python dictionary. It is very important, however, to note that building a scene dictionary requires to select a kernel variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eradiate.kernel\n",
    "eradiate.kernel.set_variant(\"scalar_mono_double\")\n",
    "from eradiate.kernel.core import ScalarTransform4f\n",
    "\n",
    "scene_dict = {\n",
    "    \"type\": \"scene\",\n",
    "    \n",
    "    # Flat rectangular diffuse surface with reflectance of 0.5\n",
    "    # and dimensions 200 km x 200 km\n",
    "    \"surface\": {\n",
    "        \"type\": \"rectangle\",\n",
    "        \"to_world\": ScalarTransform4f.scale([100, 100, 1]),\n",
    "        \"bsdf\": {\n",
    "            \"type\": \"diffuse\",\n",
    "            \"reflectance\": {\"type\": \"uniform\", \"value\": 0.5}\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # Homogeneous rayleigh-scattering plane-parallel atmosphere \n",
    "    # with dimensions 200 km x 200 km x 40 km. \n",
    "    # Value of sigma_t is arbitrary but realistic.\n",
    "    \"atmosphere\": {\n",
    "        \"type\": \"cube\",\n",
    "        \"to_world\": \n",
    "        ScalarTransform4f.translate([0, 0, 20.001]) *\n",
    "        ScalarTransform4f.scale([100, 100, 20])\n",
    "        ,\n",
    "        # The shape is translated upward so that the bottom face does\n",
    "        # not overlap with the surface\n",
    "        \"bsdf\": {\"type\": \"null\"},\n",
    "        \"interior\": {\n",
    "            \"type\": \"homogeneous\",\n",
    "            \"phase\": {\"type\": \"rayleigh\"},\n",
    "            \"sigma_t\": {\n",
    "                \"type\": \"uniform\",\n",
    "                \"value\": 1.0e-2\n",
    "            },\n",
    "            \"albedo\": {\n",
    "                \"type\": \"uniform\",\n",
    "                \"value\": 1.0\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # Directional light source with zenith angle of 30° and \n",
    "    # irradiance of 1.8 W/km^2/nm.\n",
    "    \"illumination\": {\n",
    "        \"type\": \"directional\",\n",
    "        \"direction\": [-0.5, 0, -0.8660254],\n",
    "        \"irradiance\": {\n",
    "            \"type\": \"uniform\",\n",
    "            \"value\": 1.8e6\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # Perspective camera with a 45° zenith viewing angle\n",
    "    \"measure\": {\n",
    "        \"type\": \"perspective\",\n",
    "        \"sampler\": {\n",
    "            \"type\": \"independent\",\n",
    "            \"sample_count\": 4096\n",
    "        },\n",
    "        \"film\": {\n",
    "            \"type\": \"hdrfilm\",\n",
    "            \"width\": 64,\n",
    "            \"height\": 64,\n",
    "            \"component_format\": \"float32\",\n",
    "            \"pixel_format\": \"luminance\",\n",
    "            \"rfilter\": {\"type\": \"box\"},\n",
    "        },\n",
    "        \"far_clip\": 1e7,\n",
    "        \"to_world\": ScalarTransform4f\n",
    "            .look_at(origin=[0, 400, 400],\n",
    "                     target=[0, 0, 0],\n",
    "                     up=[0, 0, 1])\n",
    "    },\n",
    "\n",
    "    # Volumetric path tracer (no multiple importance sampling)\n",
    "    \"integrator\": {\"type\": \"volpath\"}\n",
    "}\n",
    "display(scene_dict)\n",
    "\n",
    "from eradiate.kernel.core.xml import load_dict\n",
    "scene = load_dict(scene_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scene can then be rendered using the facilities we created before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render(scene)\n",
    "plot(scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel scene dictionaries are a very flexible way of interacting with the model. They are very easy to modify. For instance, let's add a few objects to the scene (floating spheres), increase the image resolution and decrease the number of samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_dict[\"measure\"][\"sampler\"][\"sample_count\"] = 512\n",
    "scene_dict[\"measure\"][\"film\"][\"height\"] = scene_dict[\"measure\"][\"film\"][\"width\"] = 256\n",
    "scene_dict[\"integrator\"][\"type\"] = \"volpath\"\n",
    "\n",
    "n_spheres = 24\n",
    "angles = np.linspace(0, 2. * np.pi, n_spheres, endpoint=False)\n",
    "cycle = 6\n",
    "\n",
    "reflectances_fwd = np.linspace(0., 1., int(cycle/2)+1)\n",
    "reflectances_bwd = reflectances_fwd[-2:-int(cycle/2)-1:-1]\n",
    "reflectances = (list(reflectances_fwd) + list(reflectances_bwd)) * int(n_spheres/cycle)\n",
    " \n",
    "for i, (angle, reflectance) in enumerate(zip(angles, reflectances)):\n",
    "    scene_dict[f\"floating_sphere_{i}\"] = {\n",
    "        \"type\": \"sphere\", \n",
    "        \"radius\": 7.5,\n",
    "        \"center\": [75. * np.cos(angle), 75. * np.sin(angle), 50],\n",
    "        \"bsdf\": {\n",
    "            \"type\": \"diffuse\",\n",
    "            \"reflectance\": {\n",
    "                \"type\": \"uniform\",\n",
    "                \"value\": reflectance * 0.75\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "scene = load_dict(scene_dict)\n",
    "render(scene)\n",
    "plt.figure(figsize=(8,6))\n",
    "plot(scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. The scene generation interface (Level-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, building a scene can become a tedious task. As scenes grow in size and complexity, writing XML files or Python dictionaries manually will become impractical—if not impossible. We typically would like to have a tool to generate kernel scenes from a convenient set of instructions.\n",
    "\n",
    "The `eradiate.scenes` package serves this purpose and contains a set of convenience classes and functions to assist the user with scene creation. Let's see how we can generate the scene we've been working on so far.\n",
    "\n",
    "The `SceneDict` class wraps an ordinary scene dictionary. It keeps track of the kernel variant with which it has been created to avoid inconsistencies: a scene dictionary created for a given kernel variant cannot be used with another kernel variant and `SceneDict` will report clearly this sort of inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import eradiate.kernel\n",
    "from eradiate.scenes import SceneDict\n",
    "eradiate.kernel.set_variant(\"scalar_mono_double\")\n",
    "\n",
    "\n",
    "scene_dict = SceneDict.empty()\n",
    "print(f\"scene_dict.variant = {scene_dict.variant}\")\n",
    "display(scene_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can start building our scene. We first add a Lambertian surface using the `Lambertian` class. A `Lambertian` instance is initialised using a dictionary which contains a set of parameters specified in the class's documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from eradiate.scenes.lithosphere import Lambertian\n",
    "\n",
    "scene_horizontal_size = 200.  # km\n",
    "\n",
    "surface = Lambertian({\n",
    "    \"reflectance\": 0.5, \n",
    "    \"width\": scene_horizontal_size,\n",
    "})\n",
    "display(surface)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Lambertian` instance can be converted into a dictionary suitable for merge with a kernel scene. By default, the BSDF plugin is defined at the top level of the scene, which allows to share it between multiple shapes and minimise resource cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = surface.kernel_dict()\n",
    "display(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each item of the dictionary can be instantiated separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from eradiate.kernel.core.xml import load_dict\n",
    "print(load_dict(surface.kernel_dict()[\"bsdf_surface\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add it to our scene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scene_dict.add(surface)\n",
    "display(scene_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can move on to adding the participating medium. This is done using the `RayleighHomogeneous` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eradiate.scenes.atmosphere import RayleighHomogeneous\n",
    "\n",
    "atmosphere = RayleighHomogeneous({\n",
    "    \"sigma_s\": 1e-2,  # km^-1\n",
    "    \"height\": 40.,  # km\n",
    "    \"width\": scene_horizontal_size  # km\n",
    "})\n",
    "\n",
    "scene_dict.add(atmosphere)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to illuminate our scene. For that purpose, we'll use the ``Directional`` class. It is parametrised in a natural way for EO scientists, using a (zenith, azimuth) pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eradiate.scenes.illumination import Directional\n",
    "\n",
    "illumination = Directional({\n",
    "    \"zenith\": 30.,\n",
    "    \"azimuth\": 0.,\n",
    "    \"irradiance\": 1.8e+6  # W/km^2/nm\n",
    "})\n",
    "\n",
    "scene_dict.add(illumination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last thing is missing in our scene: we need a sensor to record light. Since we are rebuilding the scene we created before, we'll add a perspective camera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eradiate.scenes.measure import Perspective\n",
    "\n",
    "scene_dict.add(Perspective({\n",
    "    \"target\": [0, 0, 0],\n",
    "    \"zenith\": 45.,\n",
    "    \"azimuth\": 90.,\n",
    "    \"distance\": 400. * np.sqrt(2),\n",
    "    \"res\": 64,\n",
    "    \"spp\": 4096,\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our scene is now only missing an integrator, which will specify the integration algorithm. Since we have a participating medium, we'll need a volume-enabled algorithm and use the volumetric path tracer plugin. We can mix Eradiate's scene generation helpers with kernel scene specification dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_dict.add({\"integrator\": {\"type\": \"volpath\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to run the simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = scene_dict.load()\n",
    "render(scene)\n",
    "plot(scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, this is what the complete scene creation code looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_dict = SceneDict.empty().add([\n",
    "    Lambertian({\n",
    "        \"reflectance\": 0.5, \n",
    "        \"width\": 200\n",
    "    }),\n",
    "    RayleighHomogeneous({\n",
    "        \"sigma_s\": 1e-2,\n",
    "        \"height\": 40.,\n",
    "        \"width\": 200.\n",
    "    }),\n",
    "    Directional({\n",
    "        \"zenith\": 30.,\n",
    "        \"azimuth\": 0.,\n",
    "        \"irradiance\": 1.8e+6\n",
    "    }),\n",
    "    Perspective({\n",
    "        \"target\": [0, 0, 0],\n",
    "        \"zenith\": 45.,\n",
    "        \"azimuth\": 90.,\n",
    "        \"distance\": 400. * np.sqrt(2),\n",
    "        \"res\": 64,\n",
    "        \"spp\": 4096,\n",
    "    }),\n",
    "    {\"integrator\": {\"type\": \"volpath\"}}\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, the same scene created using the Level-1 interface looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "scene_dict_manual = {\n",
    "    \"type\": \"scene\",\n",
    "    \n",
    "    # Flat rectangular diffuse surface with reflectance of 0.5\n",
    "    # and dimensions 200 km x 200 km\n",
    "    \"surface\": {\n",
    "        \"type\": \"rectangle\",\n",
    "        \"to_world\": ScalarTransform4f.scale([100, 100, 1]),\n",
    "        \"bsdf\": {\n",
    "            \"type\": \"diffuse\",\n",
    "            \"reflectance\": {\"type\": \"uniform\", \"value\": 0.5}\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # Homogeneous rayleigh-scattering plane-parallel atmosphere \n",
    "    # with dimensions 200 km x 200 km x 40 km. \n",
    "    # Value of sigma_t is arbitrary.\n",
    "    \"atmosphere\": {\n",
    "        \"type\": \"cube\",\n",
    "        \"to_world\": \n",
    "            ScalarTransform4f.translate([0, 0, 20.001]) *\n",
    "            ScalarTransform4f.scale([100, 100, 20]),\n",
    "        # The shape is translated upward so that the bottom face does\n",
    "        # not overlap with the surface\n",
    "        \"bsdf\": {\"type\": \"null\"},\n",
    "        \"interior\": {\n",
    "            \"type\": \"homogeneous\",\n",
    "            \"phase\": {\"type\": \"rayleigh\"},\n",
    "            \"sigma_t\": {\n",
    "                \"type\": \"uniform\",\n",
    "                \"value\": 1.0e-2\n",
    "            },\n",
    "            \"albedo\": {\n",
    "                \"type\": \"uniform\",\n",
    "                \"value\": 1.0\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # Directional light source with zenith angle of 30° and \n",
    "    # irradiance of 1 W/km^2/nm.\n",
    "    \"illumination\": {\n",
    "        \"type\": \"directional\",\n",
    "        \"direction\": [-0.5, 0, -0.8660254],\n",
    "        \"irradiance\": {\n",
    "            \"type\": \"uniform\",\n",
    "            \"value\": 1e6\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # Perspective camera with a 45° zenith viewing angle\n",
    "    \"measure\": {\n",
    "        \"type\": \"perspective\",\n",
    "        \"sampler\": {\n",
    "            \"type\": \"independent\",\n",
    "            \"sample_count\": 4096\n",
    "        },\n",
    "        \"film\": {\n",
    "            \"type\": \"hdrfilm\",\n",
    "            \"width\": 64,\n",
    "            \"height\": 64,\n",
    "            \"component_format\": \"float32\",\n",
    "            \"pixel_format\": \"luminance\",\n",
    "            \"rfilter\": {\"type\": \"box\"},\n",
    "        },\n",
    "        \"far_clip\": 1e7,\n",
    "        \"to_world\": ScalarTransform4f\n",
    "            .look_at(origin=[0, 400, 400],\n",
    "                     target=[0, 0, 0],\n",
    "                     up=[0, 0, 1])\n",
    "    },\n",
    "\n",
    "    # Volumetric path tracer (no multiple importance sampling)\n",
    "    \"integrator\": {\"type\": \"volpath\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. One-dimensional solver interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eradiate ships classes useful to perform specific computations. In this example, we will see how to use a generic one-dimensional solver used as the basic core of more complex applications.\n",
    "\n",
    "We start by importing the kernel and selecting a variant. We will run monochromatic simulations and therefore select the `scalar_mono_double` variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eradiate.kernel\n",
    "eradiate.kernel.set_variant(\"scalar_mono_double\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now instantiate the `OneDimSolver` class. It takes a scene geometry, optical properties and illumination, and positions sensors automatically so as to compute the radiance leaving the scene at the top of the atmosphere.\n",
    "\n",
    "`OneDimSolver` is designed to host pseudo one-dimensional scene, _i.e._ solve problems with two translational invariances. However, Eradiate's Mitsuba kernel does not exactly handle this type of symmetries; instead, a normal three-dimensional scene is used. This means that special care must be taken when creating the scene. The scene we have been working on in the rest of this tutorial is designed with that in mind: its optical thickness in the horizontal directions is such that the point (0,0,0) is out of the radiative boundary layer and will therefore not be subject to boundary effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eradiate.solvers.onedim import OneDimSolver\n",
    "from eradiate.scenes import SceneDict\n",
    "from eradiate.scenes.lithosphere import Lambertian\n",
    "from eradiate.scenes.atmosphere import RayleighHomogeneous\n",
    "from eradiate.scenes.illumination import Directional\n",
    "\n",
    "solver = OneDimSolver(SceneDict.empty().add([\n",
    "    Lambertian({\n",
    "        \"type\": \"lambertian\",\n",
    "        \"reflectance\": 0.5, \n",
    "        \"width\": 200\n",
    "    }),\n",
    "    RayleighHomogeneous({\n",
    "        \"sigma_s\": 1e-2,\n",
    "        \"height\": 40.,\n",
    "        \"width\": 200.\n",
    "    }),\n",
    "    Directional({\n",
    "        \"zenith\": 0.,\n",
    "        \"azimuth\": 0.,\n",
    "        \"irradiance\": 1.0e+6\n",
    "    }),\n",
    "    {\"integrator\": {\"type\": \"volpathmis\"}}\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this scene definition does _not_ include any sensor: the solver will take care of instantiating them and positioning them appropriately based on the angular configuration requested by the user.\n",
    "\n",
    "We can first run the simulation for a single angular configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "solver.run(\n",
    "    vza=0., \n",
    "    vaa=0.,\n",
    "    spp=32000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that since we defined our scene in kilometres, the recorded radiance is in W/km^2/sr/nm.\n",
    "\n",
    "We start the simulation with the `run` method. We specify the angular grid, as well as the number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "zenith_grid = np.arange(0., 90., 10.)\n",
    "azimuth_grid = np.arange(0., 360.1, 10.)\n",
    "\n",
    "result = solver.run(\n",
    "    vza=zenith_grid, \n",
    "    vaa=azimuth_grid,\n",
    "    spp=4096\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, theta = np.meshgrid(zenith_grid, np.radians(azimuth_grid))\n",
    "values = np.transpose(result)\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw=dict(projection='polar'))\n",
    "pcm = ax.pcolormesh(theta, r, values, cmap=\"BuPu_r\")\n",
    " \n",
    "plt.colorbar(pcm)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you can notice the noise in the output: the number of samples has been kept relatively low for this demo. There are lots of possible improvements to this solver and the scene elements we used, and they will be implemented gradually.\n",
    "\n",
    "This is the end of this demonstration. Eradiate has an even higher level of automation in store, which is showcased in the third part!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
